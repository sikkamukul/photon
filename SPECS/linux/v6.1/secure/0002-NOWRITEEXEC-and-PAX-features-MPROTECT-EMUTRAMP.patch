From a4ee0450bab7b133270e99ab236c8996df457178 Mon Sep 17 00:00:00 2001
From: Alexey Makhalov <amakhalov@vmware.com>
Date: Fri, 3 Feb 2017 07:10:18 -0800
Subject: [PATCH] NOWRITEEXEC and PAX features: MPROTECT, EMUTRAMP

NOWRITEEXEC: Is an implementation of userspace W^X memory protection policy.
W^X is a security feature in operating systems and virtual machines. It is
a memory protection policy whereby every page in a process's or kernel's
address space may be either writable or executable, but not both. Without
such protection, a program can write (as data "W") CPU instructions in an
area of memory intended for data and then run (as executable "X"; or
read-execute "RX") those instructions. This can be dangerous if the writer
of the memory is malicious. W^X is the Unix-like terminology for a strict
use of the general concept of executable space protection, controlled via
the mprotect system call. Kernel space was already W^X protected by NX
feature. NOWRITEEXEC implements similar protection for userspace processes.

NOWRITEEXEC disallow ELF program headers with WE (write and execute)
properties set at the same time. In addition NOWRITEEXEC forbids any mappings
(anonymous or file backed) to be both writable and executable.

All modern toolchain and compilers generate ELF binaries with R, RW, RE flags
only. There is an exception where GNU_STACK may have RWE. Some programs and
libraries that for one reason or another attempt to execute special small code
snippets from stack which is disallowed to be executable by NOWRITEEXEC. Most
notable examples are the signal handler return code generated by the kernel
itself and the GCC trampolines. To make those binaries happy, PaX introduced
trampolines emulation (EMUTRAMP), where kernel traps on stack execution and
emulates known sequence of instruction. For unknown pattern it faults with
W^X violation error.

MPROTECT: Enabling this option will prevent programs from
 - changing the executable status of memory pages that were not originally
   created as executable,
 - making read-only executable pages writable again,
 - creating executable pages from anonymous memory,
 - making read-only-after-relocations (RELRO) data pages writable again.

Enabling this option will prevent the injection and execution of 'foreign'
code in a program. This will also break programs that rely on the old
behaviour and expect that dynamically allocated memory via the malloc()
family of functions is executable (which it is not). Notable examples are
the XFree86 4.x server, the java runtime and wine.

PAX_XATTR_PAX_FLAGS: filesystem extended attributes marking.
Enabling this option will allow you to control PaX features on a per
executable basis via the 'setfattr' utility.  The control flags will
be read from the user.pax.flags extended attribute of the file. The main
drawback is that extended attributes are not supported by some filesystems
(e.g., isofs, udf, vfat) so copying files through such filesystems will lose
the extended attributes and these PaX markings. If you enable none of the
marking options then all applications will run with PaX enabled on them by
default.

Supported markings:
 e - EMUTRAMP disabled. Executable stack disallowed.
 E - EMUTRAMP enabled. Executable stack disallowed but emulated.
 m - MPROTECT disabled. WE mappings are allowed. Security risk!
 M - MPROTECT enabled. W^E policy is in place for all userspace mappings.
Default PaX control setings:
 "eM" - for most applications
 "EM" - for applications with RWE stack.

Per file markings can be set using setfattr tool. Example of disabling
MPROTECT for java binary:
setfattr -n user.pax.flags -v "em" /usr/lib/jvm/OpenJDK-17/bin/java

Current process settings can be fetched from /proc/<pid>/status.

URL: https://en.wikipedia.org/wiki/W^X
URL: https://lwn.net/Articles/422487/
Signed-off-by: Alexey Makhalov <amakhalov@vmware.com>
Signed-off-by: Keerthana K <keerthanak@vmware.com>
Signed-off-by: Alexey Makhalov <amakhalov@vmware.com>
---
 arch/x86/mm/fault.c        | 218 +++++++++++++++++++++++++++++++++++++
 fs/binfmt_elf.c            | 149 +++++++++++++++++++++++++
 fs/exec.c                  |   6 +
 fs/proc/array.c            |  18 +++
 include/linux/binfmts.h    |   3 +
 include/linux/elf.h        |   2 +
 include/linux/mm_types.h   |   3 +
 include/linux/sched.h      |   3 +
 include/uapi/linux/elf.h   |   2 +
 include/uapi/linux/xattr.h |   5 +
 ipc/shm.c                  |   4 +
 mm/mmap.c                  |  26 +++++
 mm/mprotect.c              |  13 +++
 mm/shmem.c                 |  37 +++++++
 security/Kconfig           |  91 ++++++++++++++++
 15 files changed, 580 insertions(+)

diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 7b0d4ab89..9a58c2507 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -166,6 +166,11 @@ is_prefetch(struct pt_regs *regs, unsigned long error_code, unsigned long addr)
 	return prefetch;
 }
 
+#ifdef CONFIG_PAX_EMUTRAMP
+static bool pax_is_fetch_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address);
+static int pax_handle_fetch_fault(struct pt_regs *regs);
+#endif
+
 DEFINE_SPINLOCK(pgd_lock);
 LIST_HEAD(pgd_list);
 
@@ -745,6 +750,13 @@ kernelmode_fixup_or_oops(struct pt_regs *regs, unsigned long error_code,
 		 */
 		if (in_interrupt())
 			return;
+#ifdef CONFIG_PAX_EMUTRAMP
+		if (pax_is_fetch_fault(regs, error_code, address)) {
+			if (pax_handle_fetch_fault(regs) == 2)
+				return;
+			do_group_exit(SIGKILL);
+		}
+#endif
 
 		/*
 		 * Per the above we're !in_interrupt(), aka. task context.
@@ -1577,3 +1589,209 @@ DEFINE_IDTENTRY_RAW_ERRORCODE(exc_page_fault)
 
 	irqentry_exit(regs, state);
 }
+
+#ifdef CONFIG_PAX_EMUTRAMP
+static bool pax_is_fetch_fault(struct pt_regs *regs, unsigned long error_code, unsigned long address)
+{
+	unsigned long ip = regs->ip;
+
+	if (v8086_mode(regs))
+		ip = ((regs->cs & 0xffff) << 4) + (ip & 0xffff);
+
+	if ((__supported_pte_mask & _PAGE_NX) && (error_code & X86_PF_INSTR))
+		return true;
+	if (!(error_code & (X86_PF_PROT | X86_PF_WRITE)) && ip == address)
+		return true;
+	return false;
+}
+
+static int pax_handle_fetch_fault_32(struct pt_regs *regs)
+{
+	int err;
+
+	do { /* PaX: libffi trampoline emulation */
+		unsigned char mov, jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 9) >> 32)
+			break;
+#endif
+
+		err = get_user(mov, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(jmp, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+
+		if (err)
+			break;
+
+		if (mov == 0xB8 && jmp == 0xE9) {
+			regs->ax = addr1;
+			regs->ip = (unsigned int)(regs->ip + addr2 + 10);
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #1 */
+		unsigned char mov1, mov2;
+		unsigned short jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 11) >> 32)
+			break;
+#endif
+
+		err = get_user(mov1, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(mov2, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+		err |= get_user(jmp, (unsigned short __user *)(regs->ip + 10));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xB9 && mov2 == 0xB8 && jmp == 0xE0FF) {
+			regs->cx = addr1;
+			regs->ax = addr2;
+			regs->ip = addr2;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #2 */
+		unsigned char mov, jmp;
+		unsigned int addr1, addr2;
+
+#ifdef CONFIG_X86_64
+		if ((regs->ip + 9) >> 32)
+			break;
+#endif
+
+		err = get_user(mov, (unsigned char __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 1));
+		err |= get_user(jmp, (unsigned char __user *)(regs->ip + 5));
+		err |= get_user(addr2, (unsigned int __user *)(regs->ip + 6));
+
+		if (err)
+			break;
+
+		if (mov == 0xB9 && jmp == 0xE9) {
+			regs->cx = addr1;
+			regs->ip = (unsigned int)(regs->ip + addr2 + 10);
+			return 2;
+		}
+	} while (0);
+
+	return 1; /* PaX in action */
+}
+
+#ifdef CONFIG_X86_64
+static int pax_handle_fetch_fault_64(struct pt_regs *regs)
+{
+	int err;
+
+	do { /* PaX: libffi trampoline emulation */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char stcclc, jmp2;
+		unsigned long addr1, addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned long __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 10));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 12));
+		err |= get_user(stcclc, (unsigned char __user *)(regs->ip + 20));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 21));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 23));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB49 && mov2 == 0xBA49 && (stcclc == 0xF8 || stcclc == 0xF9) && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			if (stcclc == 0xF8)
+				regs->flags &= ~X86_EFLAGS_CF;
+			else
+				regs->flags |= X86_EFLAGS_CF;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #1 */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char jmp2;
+		unsigned int addr1;
+		unsigned long addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned int __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 6));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 8));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 16));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 18));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB41 && mov2 == 0xBA49 && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	do { /* PaX: gcc trampoline emulation #2 */
+		unsigned short mov1, mov2, jmp1;
+		unsigned char jmp2;
+		unsigned long addr1, addr2;
+
+		err = get_user(mov1, (unsigned short __user *)regs->ip);
+		err |= get_user(addr1, (unsigned long __user *)(regs->ip + 2));
+		err |= get_user(mov2, (unsigned short __user *)(regs->ip + 10));
+		err |= get_user(addr2, (unsigned long __user *)(regs->ip + 12));
+		err |= get_user(jmp1, (unsigned short __user *)(regs->ip + 20));
+		err |= get_user(jmp2, (unsigned char __user *)(regs->ip + 22));
+
+		if (err)
+			break;
+
+		if (mov1 == 0xBB49 && mov2 == 0xBA49 && jmp1 == 0xFF49 && jmp2 == 0xE3) {
+			regs->r11 = addr1;
+			regs->r10 = addr2;
+			regs->ip = addr1;
+			return 2;
+		}
+	} while (0);
+
+	return 1; /* PaX in action */
+}
+#endif
+
+/*
+ * PaX: decide what to do with offenders (regs->ip = fault address)
+ *
+ * returns 1 when task should be killed
+ *         2 when gcc trampoline was detected
+ */
+static int pax_handle_fetch_fault(struct pt_regs *regs)
+{
+	if (v8086_mode(regs))
+		return 1;
+
+	if (!(current->mm->pax_flags & MF_PAX_EMUTRAMP))
+		return 1;
+
+#ifdef CONFIG_X86_32
+	return pax_handle_fetch_fault_32(regs);
+#else
+	if (regs->cs == __USER32_CS || (regs->cs & SEGMENT_LDT))
+		return pax_handle_fetch_fault_32(regs);
+	else
+		return pax_handle_fetch_fault_64(regs);
+#endif
+}
+#endif
diff --git a/fs/binfmt_elf.c b/fs/binfmt_elf.c
index 444302afc..d9a8f88db 100644
--- a/fs/binfmt_elf.c
+++ b/fs/binfmt_elf.c
@@ -45,6 +45,7 @@
 #include <linux/types.h>
 #include <linux/cred.h>
 #include <linux/dax.h>
+#include <linux/xattr.h>
 #include <linux/uaccess.h>
 #include <asm/param.h>
 #include <asm/page.h>
@@ -83,6 +84,10 @@ static int elf_core_dump(struct coredump_params *cprm);
 #define elf_core_dump	NULL
 #endif
 
+#ifdef CONFIG_PAX_MPROTECT
+static void elf_handle_mprotect(struct vm_area_struct *vma, unsigned long newflags);
+#endif
+
 #if ELF_EXEC_PAGESIZE > PAGE_SIZE
 #define ELF_MIN_ALIGN	ELF_EXEC_PAGESIZE
 #else
@@ -103,6 +108,9 @@ static struct linux_binfmt elf_format = {
 	.load_shlib	= load_elf_library,
 #ifdef CONFIG_COREDUMP
 	.core_dump	= elf_core_dump,
+#ifdef CONFIG_PAX_MPROTECT
+	.handle_mprotect= elf_handle_mprotect,
+#endif
 	.min_coredump	= ELF_EXEC_PAGESIZE,
 #endif
 };
@@ -821,6 +829,77 @@ static int parse_elf_properties(struct file *f, const struct elf_phdr *phdr,
 	return ret == -ENOENT ? 0 : ret;
 }
 
+#if defined(CONFIG_PAX_XATTR_PAX_FLAGS)
+static ssize_t pax_getxattr(struct file * const file, void *value, size_t size)
+{
+	struct dentry *dentry = file->f_path.dentry;
+	struct inode *inode = dentry->d_inode;
+	ssize_t error;
+
+	error = inode_permission(file_mnt_user_ns(file), inode, MAY_EXEC);
+	if (error)
+		return error;
+
+	return __vfs_getxattr(dentry, inode, XATTR_NAME_USER_PAX_FLAGS, value, size);
+}
+
+static void pax_parse_xattr_pax(struct file * const file, int *m, int *e)
+{
+
+	ssize_t xattr_size, i;
+	unsigned char xattr_value[sizeof("em") - 1];
+
+	xattr_size = pax_getxattr(file, xattr_value, sizeof xattr_value);
+	if (xattr_size < 0 || xattr_size > sizeof xattr_value)
+		return;
+
+	for (i = 0; i < xattr_size; i++)
+		switch (xattr_value[i]) {
+		case 'm':
+			*m = 0;
+			break;
+		case 'M':
+			*m = MF_PAX_MPROTECT;
+			break;
+		case 'e':
+			*e = 0;
+			break;
+		case 'E':
+			*e = MF_PAX_EMUTRAMP;
+			break;
+		}
+}
+
+static long pax_parse_pax_flags(struct file * const file)
+{
+	int fm = -1, fe = -1;
+	unsigned long pax_flags = current->mm->pax_flags;
+
+	pax_parse_xattr_pax(file, &fm, &fe);
+
+	/* MPROTECT: overwrite from xattr */
+	if (fm != -1) {
+		pax_flags &= ~MF_PAX_MPROTECT;
+		pax_flags |= fm;
+	}
+
+	/* EMUTRAMP: sanity check */
+	if (fe == MF_PAX_EMUTRAMP) {
+		pax_flags |= MF_PAX_EMUTRAMP;
+	} else if (!fe){
+		if (pax_flags & MF_PAX_EMUTRAMP) {
+			pr_err("PAX: %s[%d] needs an executable stack. Can not disable EMUTRAMP. Please fix 'e' bit in "
+					XATTR_NAME_USER_PAX_FLAGS " xattr.",
+					current->comm, task_pid_nr(current));
+			return -EINVAL;
+		}
+	}
+
+	current->mm->pax_flags = pax_flags;
+	return 0;
+}
+#endif
+
 static int load_elf_binary(struct linux_binprm *bprm)
 {
 	struct file *interpreter = NULL; /* to shut gcc up */
@@ -1006,6 +1085,23 @@ static int load_elf_binary(struct linux_binprm *bprm)
 	/* Do this immediately, since STACK_TOP as used in setup_arg_pages
 	   may depend on the personality.  */
 	SET_PERSONALITY2(*elf_ex, &arch_state);
+#if defined(CONFIG_PAX_NOWRITEEXEC)
+	/* Enable MPROTECT by default */
+	current->mm->pax_flags = MF_PAX_MPROTECT;
+#if defined(CONFIG_PAX_EMUTRAMP)
+	/* Enable EMUTRAMP if ELF requires executable stack */
+	if (executable_stack == EXSTACK_ENABLE_X)
+	{
+		executable_stack = EXSTACK_DISABLE_X;
+		current->mm->pax_flags |= MF_PAX_EMUTRAMP;
+	}
+#endif
+#if defined(CONFIG_PAX_XATTR_PAX_FLAGS)
+	retval = pax_parse_pax_flags(bprm->file);
+	if (retval < 0)
+		goto out_free_dentry;
+#endif
+#endif
 	if (elf_read_implies_exec(*elf_ex, executable_stack))
 		current->personality |= READ_IMPLIES_EXEC;
 
@@ -2330,6 +2426,59 @@ static int elf_core_dump(struct coredump_params *cprm)
 
 #endif		/* CONFIG_ELF_CORE */
 
+#ifdef CONFIG_PAX_MPROTECT
+/* PaX: non-PIC ELF libraries need relocations on their executable segments
+ * therefore we'll grant them VM_MAYWRITE once during their life. Similarly
+ * we'll remove VM_MAYWRITE for good on RELRO segments.
+ *
+ * The checks favour ld-linux.so behaviour which operates on a per ELF segment
+ * basis because we want to allow the common case and not the special ones.
+ */
+static void elf_handle_mprotect(struct vm_area_struct *vma, unsigned long newflags)
+{
+	struct elfhdr elf_h;
+	struct elf_phdr elf_p;
+	unsigned long i;
+	unsigned long oldflags;
+	bool is_relro;
+	loff_t pos;
+
+	if (!(vma->vm_mm->pax_flags & MF_PAX_MPROTECT) || !vma->vm_file)
+		return;
+
+	oldflags = vma->vm_flags & (VM_MAYEXEC | VM_MAYWRITE | VM_MAYREAD | VM_EXEC | VM_WRITE | VM_READ);
+	newflags &= VM_MAYEXEC | VM_MAYWRITE | VM_MAYREAD | VM_EXEC | VM_WRITE | VM_READ;
+
+	/* possible RELRO */
+	is_relro = vma->anon_vma && oldflags == (VM_MAYWRITE | VM_MAYREAD | VM_READ) && newflags == (VM_MAYWRITE | VM_MAYREAD | VM_READ);
+
+	if (!is_relro)
+		return;
+
+	pos = 0UL;
+	if (sizeof(elf_h) != kernel_read(vma->vm_file, (char *)&elf_h, sizeof(elf_h), &pos) ||
+	    memcmp(elf_h.e_ident, ELFMAG, SELFMAG) ||
+	    (elf_h.e_type != ET_DYN && elf_h.e_type != ET_EXEC) ||
+	    !elf_check_arch(&elf_h) ||
+	    elf_h.e_phentsize != sizeof(struct elf_phdr) ||
+	    elf_h.e_phnum > 65536UL / sizeof(struct elf_phdr))
+		return;
+
+	for (i = 0UL; i < elf_h.e_phnum; i++) {
+		pos = elf_h.e_phoff + i*sizeof(elf_p);
+		if (sizeof(elf_p) != kernel_read(vma->vm_file, (char *)&elf_p, sizeof(elf_p), &pos))
+			return;
+		if (elf_p.p_type == PT_GNU_RELRO) {
+			if (!is_relro)
+				continue;
+			if ((elf_p.p_offset >> PAGE_SHIFT) == vma->vm_pgoff && ELF_PAGEALIGN(elf_p.p_memsz) == vma->vm_end - vma->vm_start)
+				vma->vm_flags &= ~VM_MAYWRITE;
+			is_relro = false;
+		}
+	}
+}
+#endif
+
 static int __init init_elf_binfmt(void)
 {
 	register_binfmt(&elf_format);
diff --git a/fs/exec.c b/fs/exec.c
index a0b1f0337..91925ca79 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -807,7 +807,13 @@ int setup_arg_pages(struct linux_binprm *bprm,
 	if (unlikely(executable_stack == EXSTACK_ENABLE_X))
 		vm_flags |= VM_EXEC;
 	else if (executable_stack == EXSTACK_DISABLE_X)
+	{
 		vm_flags &= ~VM_EXEC;
+#ifdef CONFIG_PAX_MPROTECT
+		if (mm->pax_flags & MF_PAX_MPROTECT)
+			vm_flags &= ~VM_MAYEXEC;
+#endif
+	}
 	vm_flags |= mm->def_flags;
 	vm_flags |= VM_STACK_INCOMPLETE_SETUP;
 
diff --git a/fs/proc/array.c b/fs/proc/array.c
index 49283b810..1ee4742e4 100644
--- a/fs/proc/array.c
+++ b/fs/proc/array.c
@@ -428,6 +428,19 @@ static inline void task_thp_status(struct seq_file *m, struct mm_struct *mm)
 	seq_printf(m, "THP_enabled:\t%d\n", thp_enabled);
 }
 
+#if defined(CONFIG_PAX_NOWRITEEXEC)
+static inline void task_pax(struct seq_file *m, struct task_struct *p)
+{
+	if (p->mm)
+		seq_printf(m, "PaX:\t%c%c\n",
+			p->mm->pax_flags & MF_PAX_EMUTRAMP ? 'E' : 'e',
+			p->mm->pax_flags & MF_PAX_MPROTECT ? 'M' : 'm');
+	else
+		seq_printf(m, "PaX:\t--\n");
+}
+#endif
+
+
 int proc_pid_status(struct seq_file *m, struct pid_namespace *ns,
 			struct pid *pid, struct task_struct *task)
 {
@@ -451,6 +464,11 @@ int proc_pid_status(struct seq_file *m, struct pid_namespace *ns,
 	task_cpus_allowed(m, task);
 	cpuset_task_status_allowed(m, task);
 	task_context_switch_counts(m, task);
+
+#if defined(CONFIG_PAX_NOWRITEEXEC)
+	task_pax(m, task);
+#endif
+
 	return 0;
 }
 
diff --git a/include/linux/binfmts.h b/include/linux/binfmts.h
index 8d51f69f9..1e2c70230 100644
--- a/include/linux/binfmts.h
+++ b/include/linux/binfmts.h
@@ -86,6 +86,9 @@ struct linux_binfmt {
 	int (*load_shlib)(struct file *);
 #ifdef CONFIG_COREDUMP
 	int (*core_dump)(struct coredump_params *cprm);
+#ifdef CONFIG_PAX_MPROTECT
+	void (*handle_mprotect)(struct vm_area_struct *vma, unsigned long newflags);
+#endif
 	unsigned long min_coredump;	/* minimal dump size */
 #endif
 } __randomize_layout;
diff --git a/include/linux/elf.h b/include/linux/elf.h
index c9a46c4e1..8646a6b22 100644
--- a/include/linux/elf.h
+++ b/include/linux/elf.h
@@ -46,6 +46,7 @@ extern Elf32_Dyn _DYNAMIC [];
 #define Elf_Half	Elf32_Half
 #define Elf_Word	Elf32_Word
 #define ELF_GNU_PROPERTY_ALIGN	ELF32_GNU_PROPERTY_ALIGN
+#define elf_dyn		Elf32_Dyn
 
 #else
 
@@ -58,6 +59,7 @@ extern Elf64_Dyn _DYNAMIC [];
 #define Elf_Half	Elf64_Half
 #define Elf_Word	Elf64_Word
 #define ELF_GNU_PROPERTY_ALIGN	ELF64_GNU_PROPERTY_ALIGN
+#define elf_dyn		Elf64_Dyn
 
 #endif
 
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 247aedb18..8399506d0 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -684,6 +684,9 @@ struct mm_struct {
 		atomic_long_t hugetlb_usage;
 #endif
 		struct work_struct async_put_work;
+#if defined(CONFIG_PAX_NOWRITEEXEC)
+		unsigned long pax_flags;
+#endif
 
 #ifdef CONFIG_IOMMU_SVA
 		u32 pasid;
diff --git a/include/linux/sched.h b/include/linux/sched.h
index ffb6eb55c..7e80d3e6a 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1306,6 +1306,9 @@ struct task_struct {
 	unsigned long			numa_pages_migrated;
 #endif /* CONFIG_NUMA_BALANCING */
 
+#define MF_PAX_EMUTRAMP		0x02000000	/* Emulate trampolines */
+#define MF_PAX_MPROTECT		0x04000000	/* Restrict mprotect() */
+
 #ifdef CONFIG_RSEQ
 	struct rseq __user *rseq;
 	u32 rseq_sig;
diff --git a/include/uapi/linux/elf.h b/include/uapi/linux/elf.h
index c7b056af9..c10d0910e 100644
--- a/include/uapi/linux/elf.h
+++ b/include/uapi/linux/elf.h
@@ -100,6 +100,8 @@ typedef __s64	Elf64_Sxword;
 #define DT_DEBUG	21
 #define DT_TEXTREL	22
 #define DT_JMPREL	23
+#define DT_FLAGS	30
+  #define DF_TEXTREL  0x00000004
 #define DT_ENCODING	32
 #define OLD_DT_LOOS	0x60000000
 #define DT_LOOS		0x6000000d
diff --git a/include/uapi/linux/xattr.h b/include/uapi/linux/xattr.h
index 9463db2df..d4264c8df 100644
--- a/include/uapi/linux/xattr.h
+++ b/include/uapi/linux/xattr.h
@@ -81,5 +81,10 @@
 #define XATTR_POSIX_ACL_DEFAULT  "posix_acl_default"
 #define XATTR_NAME_POSIX_ACL_DEFAULT XATTR_SYSTEM_PREFIX XATTR_POSIX_ACL_DEFAULT
 
+/* User namespace */
+#define XATTR_PAX_PREFIX "pax."
+#define XATTR_PAX_FLAGS_SUFFIX "flags"
+#define XATTR_NAME_USER_PAX_FLAGS XATTR_USER_PREFIX XATTR_PAX_PREFIX XATTR_PAX_FLAGS_SUFFIX
+#define XATTR_NAME_PAX_FLAGS XATTR_PAX_PREFIX XATTR_PAX_FLAGS_SUFFIX
 
 #endif /* _UAPI_LINUX_XATTR_H */
diff --git a/ipc/shm.c b/ipc/shm.c
index bd2fcc4d4..ac5e177c2 100644
--- a/ipc/shm.c
+++ b/ipc/shm.c
@@ -1572,6 +1572,10 @@ long do_shmat(int shmid, char __user *shmaddr, int shmflg,
 		f_flags = O_RDWR;
 	}
 	if (shmflg & SHM_EXEC) {
+#ifdef CONFIG_PAX_MPROTECT
+		if (current->mm->pax_flags & MF_PAX_MPROTECT)
+			goto out;
+#endif
 		prot |= PROT_EXEC;
 		acc_mode |= S_IXUGO;
 	}
diff --git a/mm/mmap.c b/mm/mmap.c
index 14ca25918..59e5c74f1 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -1306,6 +1306,17 @@ unsigned long do_mmap(struct file *file, unsigned long addr,
 	vm_flags = calc_vm_prot_bits(prot, pkey) | calc_vm_flag_bits(flags) |
 			mm->def_flags | VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC;
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->pax_flags & MF_PAX_MPROTECT) {
+		if ((vm_flags & (VM_WRITE | VM_EXEC)) == (VM_WRITE | VM_EXEC))
+			return -EPERM;
+		if (!(vm_flags & VM_EXEC))
+			vm_flags &= ~VM_MAYEXEC;
+		else
+			vm_flags &= ~VM_MAYWRITE;
+	}
+#endif
+
 	if (flags & MAP_LOCKED)
 		if (!can_do_mlock())
 			return -EPERM;
@@ -2974,6 +2985,10 @@ static int do_brk_flags(struct ma_state *mas, struct vm_area_struct *vma,
 	 * Note: This happens *after* clearing old mappings in some code paths.
 	 */
 	flags |= VM_DATA_DEFAULT_FLAGS | VM_ACCOUNT | mm->def_flags;
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->pax_flags & MF_PAX_MPROTECT)
+		flags &= ~VM_MAYEXEC;
+#endif
 	if (!may_expand_vm(mm, flags, len >> PAGE_SHIFT))
 		return -ENOMEM;
 
@@ -3433,6 +3448,17 @@ static struct vm_area_struct *__install_special_mapping(
 	vma->vm_start = addr;
 	vma->vm_end = addr + len;
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->pax_flags & MF_PAX_MPROTECT) {
+		if ((vm_flags & (VM_WRITE | VM_EXEC)) == (VM_WRITE | VM_EXEC))
+			return ERR_PTR(-EPERM);
+		if (!(vm_flags & VM_EXEC))
+			vm_flags &= ~VM_MAYEXEC;
+		else
+			vm_flags &= ~VM_MAYWRITE;
+	}
+#endif
+
 	vma->vm_flags = vm_flags | mm->def_flags | VM_DONTEXPAND | VM_SOFTDIRTY;
 	vma->vm_flags &= VM_LOCKED_CLEAR_MASK;
 	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
diff --git a/mm/mprotect.c b/mm/mprotect.c
index 668bfaa6e..4fe86436b 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -26,6 +26,10 @@
 #include <linux/perf_event.h>
 #include <linux/pkeys.h>
 #include <linux/ksm.h>
+#ifdef CONFIG_PAX_MPROTECT
+#include <linux/elf.h>
+#include <linux/binfmts.h>
+#endif
 #include <linux/uaccess.h>
 #include <linux/mm_inline.h>
 #include <linux/pgtable.h>
@@ -631,6 +635,10 @@ mprotect_fixup(struct mmu_gather *tlb, struct vm_area_struct *vma,
 	 * held in write mode.
 	 */
 	vma->vm_flags = newflags;
+#ifdef CONFIG_PAX_MPROTECT
+	if (mm->binfmt && mm->binfmt->handle_mprotect)
+		mm->binfmt->handle_mprotect(vma, newflags);
+#endif
 	/*
 	 * We want to check manually if we can change individual PTEs writable
 	 * if we can't do that automatically for all PTEs in a mapping. For
@@ -739,6 +747,11 @@ static int do_mprotect_pkey(unsigned long start, size_t len,
 	else
 		prev = mas_prev(&mas, 0);
 
+#ifdef CONFIG_PAX_MPROTECT
+	if (current->mm->binfmt && current->mm->binfmt->handle_mprotect)
+		current->mm->binfmt->handle_mprotect(vma, calc_vm_prot_bits(prot, 0));
+#endif
+
 	tlb_gather_mmu(&tlb, current->mm);
 	for (nstart = start ; ; ) {
 		unsigned long mask_off_old_flags;
diff --git a/mm/shmem.c b/mm/shmem.c
index a8d9fd039..e682ad202 100644
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@ -3315,6 +3315,31 @@ static int shmem_xattr_handler_set(const struct xattr_handler *handler,
 	return err;
 }
 
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+static int shmem_user_xattr_handler_set(const struct xattr_handler *handler,
+				   struct user_namespace *mnt_userns,
+				   struct dentry *unused, struct inode *inode,
+				   const char *name, const void *value,
+				   size_t size, int flags)
+{
+	struct shmem_inode_info *info = SHMEM_I(inode);
+	int err;
+
+	if (strcmp(name, XATTR_NAME_PAX_FLAGS))
+		return -EOPNOTSUPP;
+	if (size > 2)
+		return -EINVAL;
+
+	name = xattr_full_name(handler, name);
+	err = simple_xattr_set(&info->xattrs, name, value, size, flags, NULL);
+	if (!err) {
+		inode->i_ctime = current_time(inode);
+		inode_inc_iversion(inode);
+	}
+	return err;
+}
+#endif
+
 static const struct xattr_handler shmem_security_xattr_handler = {
 	.prefix = XATTR_SECURITY_PREFIX,
 	.get = shmem_xattr_handler_get,
@@ -3327,6 +3352,14 @@ static const struct xattr_handler shmem_trusted_xattr_handler = {
 	.set = shmem_xattr_handler_set,
 };
 
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+static const struct xattr_handler shmem_user_xattr_handler = {
+	.prefix = XATTR_USER_PREFIX,
+	.get = shmem_xattr_handler_get,
+	.set = shmem_user_xattr_handler_set,
+};
+#endif
+
 static const struct xattr_handler *shmem_xattr_handlers[] = {
 #ifdef CONFIG_TMPFS_POSIX_ACL
 	&posix_acl_access_xattr_handler,
@@ -3334,6 +3367,10 @@ static const struct xattr_handler *shmem_xattr_handlers[] = {
 #endif
 	&shmem_security_xattr_handler,
 	&shmem_trusted_xattr_handler,
+#ifdef CONFIG_PAX_XATTR_PAX_FLAGS
+	/* Allow pax xattr for tmpfs */
+	&shmem_user_xattr_handler,
+#endif
 	NULL
 };
 
diff --git a/security/Kconfig b/security/Kconfig
index e6db09a77..0a1c517da 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -5,6 +5,97 @@
 
 menu "Security options"
 
+menuconfig PAX
+	bool "Enable various PaX features"
+	depends on X86
+	help
+	  This allows you to enable various PaX features.  PaX adds
+	  intrusion prevention mechanisms to the kernel that reduce
+	  the risks posed by exploitable memory corruption bugs.
+
+if PAX
+config PAX_NOWRITEEXEC
+	bool "Enforce non-executable pages"
+	depends on X86
+	help
+	  Enforces writables pages to be non-executable (such as the stack
+	  or heap). And enforces executable pages to be non-writable.
+
+	  Enabling this option will prevent the injection and execution of
+	  'foreign' code in a program.
+
+	  This will also break programs that rely on the old behaviour and
+	  expect that dynamically allocated memory via the malloc() family
+	  of functions is executable (which it is not).  Notable examples
+	  are the XFree86 4.x server, the java runtime and wine.
+
+if PAX_NOWRITEEXEC
+config PAX_EMUTRAMP
+	bool "Executable stack emulation"
+	help
+	  There are some programs and libraries that for one reason or
+	  another attempt to execute special small code snippets from
+	  non executable stack.  Most notable examples are the
+	  signal handler return code generated by the kernel itself and
+	  the GCC trampolines.
+
+	  If you enabled CONFIG_NOWRITEEXEC then such programs will no
+	  longer work under your kernel.
+
+	  As a remedy you can say Y here enable trampoline emulation for
+	  the affected programs yet still have the protection provided by
+	  the non-executable pages.
+
+	  NOTE: enabling this feature *may* open up a loophole in the
+	  protection provided by non-executable pages that an attacker
+	  could abuse.  Therefore the best solution is to not have any
+	  files on your system that would require this option.  This can
+	  be achieved by not using libc5 (which relies on the kernel
+	  signal handler return code) and not using or rewriting programs
+	  that make use of the nested function implementation of GCC.
+	  Skilled users can just fix GCC itself so that it implements
+	  nested function calls in a way that does not interfere with PaX.
+
+config PAX_MPROTECT
+	bool "Restrict mprotect()"
+	help
+	  Enabling this option will prevent programs from
+	   - changing the executable status of memory pages that were
+	     not originally created as executable,
+	   - making read-only executable pages writable again,
+	   - creating executable pages from anonymous memory,
+	   - making read-only-after-relocations (RELRO) data pages writable again.
+
+	  You should say Y here to complete the protection provided by
+	  the enforcement of non-executable pages.
+
+config PAX_XATTR_PAX_FLAGS
+	bool 'Use filesystem extended attributes marking'
+	select CIFS_XATTR if CIFS
+	select EXT2_FS_XATTR if EXT2_FS
+	select EXT3_FS_XATTR if EXT3_FS
+	select F2FS_FS_XATTR if F2FS_FS
+	select JFFS2_FS_XATTR if JFFS2_FS
+	select REISERFS_FS_XATTR if REISERFS_FS
+	select SQUASHFS_XATTR if SQUASHFS
+	select TMPFS_XATTR if TMPFS
+	help
+	  Enabling this option will allow you to control PaX features on
+	  a per executable basis via the 'setfattr' utility.  The control
+	  flags will be read from the user.pax.flags extended attribute of
+	  the file.  This marking has the benefit of supporting binary-only
+	  applications that self-check themselves (e.g., skype) and would
+	  not tolerate chpax/paxctl changes.  The main drawback is that
+	  extended attributes are not supported by some filesystems (e.g.,
+	  isofs, udf, vfat) so copying files through such filesystems will
+	  lose the extended attributes and these PaX markings.
+
+	  If you enable none of the marking options then all applications
+	  will run with PaX enabled on them by default.
+
+endif
+endif
+
 source "security/keys/Kconfig"
 
 config SECURITY_DMESG_RESTRICT
-- 
2.39.0

