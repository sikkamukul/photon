From d9b250aaf2e7eaf252c6d9f1df2559631c26d0d5 Mon Sep 17 00:00:00 2001
From: Cyprien Laplace <claplace@vmware.com>
Date: Fri, 29 Nov 2019 16:27:46 -0500
Subject: [PATCH 4/6] vmw_vmci: add arm64 support

VMCI is using PCI IO ports for datagram communication and shared
memory for queue pairs. Both need updates for arm64 support.

Replace inefficient one byte at a time arm64 implementations of
ioread8_rep() and iowrite8_rep() with a single VM exit hypercall.

Add virtualization specific barriers for queue pair (de)queueing,
following the core-api/circular-buffers.rst example, that will
map to actual memory barrier instructions on arm64.

Disable driver if 16KB or 64KB pages are selected as the VMware
hypervisor assumes 4KB page size at the moment.

Tested with open-vm-tools, vmw_balloon and vsock mixedTest on arm64.

Signed-off-by: Cyprien Laplace <claplace@vmware.com>
Signed-off-by: Keerthana K <keerthanak@vmware.com>
---
 MAINTAINERS                        |   1 +
 arch/arm64/include/asm/vmware.h    | 122 +++++++++++++++++++++++++++++
 arch/x86/include/asm/vmware.h      |   6 ++
 drivers/misc/vmw_vmci/Kconfig      |   3 +-
 drivers/misc/vmw_vmci/vmci_guest.c |  20 ++---
 include/linux/vmw_vmci_defs.h      |  13 ++-
 6 files changed, 153 insertions(+), 12 deletions(-)
 create mode 100644 arch/arm64/include/asm/vmware.h

diff --git a/MAINTAINERS b/MAINTAINERS
index 9d443cc32..972fb8e4f 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -18735,6 +18735,7 @@ M:	"VMware, Inc." <pv-drivers@vmware.com>
 L:	virtualization@lists.linux-foundation.org
 S:	Supported
 F:	arch/arm64/kernel/vmware.c
+F:	arch/arm64/include/asm/vmware.h
 F:	arch/arm64/kernel/hypervisor.c
 F:	arch/arm64/include/asm/hypervisor.h
 
diff --git a/arch/arm64/include/asm/vmware.h b/arch/arm64/include/asm/vmware.h
new file mode 100644
index 000000000..6a6734eb0
--- /dev/null
+++ b/arch/arm64/include/asm/vmware.h
@@ -0,0 +1,122 @@
+/* SPDX-License-Identifier: GPL-2.0 or MIT */
+/*
+ * Copyright (C) 2021, VMware, Inc.
+ * Author : Cyprien Laplace <claplace@vmware.com>
+ */
+#ifndef _ASM_ARM64_VMWARE_H
+#define _ASM_ARM64_VMWARE_H
+
+#include <asm/memory.h>
+
+/*
+ * Encoding for virtual I/O port translation: HVC 0x86 allows efficient
+ * drop-in replacement for x86 [REP] IN/INS/OUT/OUTS instructions used
+ * for backdoors and virtual devices.
+ */
+#define X86_IO_MAGIC          0x86
+/*
+ * Transfer size, bits [1:0]
+ *    00: 1 byte
+ *    01: 2 bytes
+ *    10: 4 bytes
+ *    11: Invalid value
+ */
+#define X86_IO_W7_SIZE_SHIFT  0
+/*
+ * Transfer direction, bit [2]
+ *    0: Write (OUT/OUTS/REP OUTS instructions)
+ *    1: Read (IN/INS/REP INS instructions)
+ */
+#define X86_IO_W7_DIR         BIT(2)
+/*
+ * Instruction type, bits [4:3]
+ *    00: Non-string instruction (IN/OUT) without DX register
+ *        The port address (8-bit immediate) is set in W7<12:5>.
+ *
+ *    01: Non-string instruction (IN/OUT) with DX register
+ *
+ *    10: String instruction without REP prefix (INS/OUTS)
+ *        The direction flag (EFLAGS.DF) is set in W7<5>.
+ *
+ *    11: String instruction with REP prefix (REP INS/REP OUTS)
+ *        The direction flag (EFLAGS.DF) is set in W7<5>.
+ */
+#define X86_IO_W7_WITH        BIT(3)
+#define X86_IO_W7_STR         BIT(4)
+#define X86_IO_W7_DF          BIT(5)
+
+#define VMWARE_HYPERVISOR_PORT    0x5658
+#define VMWARE_HYPERVISOR_PORT_HB 0x5659
+
+
+/*
+ * Efficient I/O port accesses for vmware virtual machines. Execute
+ * a single VM exit instead of one per byte. This feature is limitied
+ * to the first 64K I/O ports.
+ */
+
+static inline void __vmw_rep_outsb(u16 port, const void *buffer,
+				   unsigned int count)
+{
+	register u64 x2 asm("x2") = count;
+	register u32 w3 asm("w3") = port;
+	register u64 x4 asm("x4") = (u64)buffer;
+	register u32 w7 asm("w7") =   X86_IO_W7_STR
+				    | X86_IO_W7_WITH;
+
+	asm volatile(
+		"hvc %4" :
+		"+r" (x2),
+		"+r" (x4) :
+		"r" (w3),
+		"r" (w7),
+		"i" (X86_IO_MAGIC)
+	);
+}
+
+static inline void vmw_iowrite8_rep(void __iomem *addr,
+				    const void *buffer,
+				    unsigned int count)
+{
+	unsigned long port = (unsigned long)addr - PCI_IO_START;
+
+	if (WARN_ONCE((u16)port != port, "Invalid I/O address\n"))
+		return;
+
+	__vmw_rep_outsb(port, buffer, count);
+}
+
+static inline void __vmw_rep_insb(u16 port, void *buffer,
+				  unsigned int count)
+{
+	register u64 x2 asm("x2") = count;
+	register u32 w3 asm("w3") = port;
+	register u64 x5 asm("x5") = (u64)buffer;
+	register u32 w7 asm("w7") =   X86_IO_W7_STR
+				    | X86_IO_W7_WITH
+				    | X86_IO_W7_DIR;
+
+	asm volatile(
+		"hvc %4" :
+		"+r" (x2),
+		"+r" (x5) :
+		"r" (w3),
+		"r" (w7),
+		"i" (X86_IO_MAGIC) :
+		"memory"
+	);
+}
+
+static inline void vmw_ioread8_rep(const void __iomem *addr,
+				   void *buffer,
+				   unsigned int count)
+{
+	unsigned long port = (unsigned long)addr - PCI_IO_START;
+
+	if (WARN_ONCE((u16)port != port, "Invalid I/O address\n"))
+		return;
+
+	__vmw_rep_insb(port, buffer, count);
+}
+
+#endif /* _ASM_ARM64_VMWARE_H */
diff --git a/arch/x86/include/asm/vmware.h b/arch/x86/include/asm/vmware.h
index e88c50442..0a537d62f 100644
--- a/arch/x86/include/asm/vmware.h
+++ b/arch/x86/include/asm/vmware.h
@@ -7,6 +7,12 @@
 #include <asm/alternative.h>
 #include <linux/stringify.h>
 
+/*
+ * Standard I/O port access for virtual devices.
+ */
+#define vmw_iowrite8_rep iowrite8_rep
+#define vmw_ioread8_rep ioread8_rep
+
 #define CPUID_VMWARE_INFO_LEAF               0x40000000
 #define CPUID_VMWARE_FEATURES_LEAF           0x40000010
 #define CPUID_VMWARE_FEATURES_ECX_VMMCALL    BIT(0)
diff --git a/drivers/misc/vmw_vmci/Kconfig b/drivers/misc/vmw_vmci/Kconfig
index 605794aad..566a6e751 100644
--- a/drivers/misc/vmw_vmci/Kconfig
+++ b/drivers/misc/vmw_vmci/Kconfig
@@ -5,7 +5,8 @@
 
 config VMWARE_VMCI
 	tristate "VMware VMCI Driver"
-	depends on X86 && PCI
+	depends on (X86 || ARM64) && PCI
+	depends on !ARM64_16K_PAGES && !ARM64_64K_PAGES && !CPU_BIG_ENDIAN
 	help
 	  This is VMware's Virtual Machine Communication Interface.  It enables
 	  high-speed communication between host and guest in a virtual
diff --git a/drivers/misc/vmw_vmci/vmci_guest.c b/drivers/misc/vmw_vmci/vmci_guest.c
index cc8eeb361..1d32759b3 100644
--- a/drivers/misc/vmw_vmci/vmci_guest.c
+++ b/drivers/misc/vmw_vmci/vmci_guest.c
@@ -21,6 +21,8 @@
 #include <linux/io.h>
 #include <linux/vmalloc.h>
 
+#include <asm/vmware.h>
+
 #include "vmci_datagram.h"
 #include "vmci_doorbell.h"
 #include "vmci_context.h"
@@ -114,8 +116,8 @@ int vmci_send_datagram(struct vmci_datagram *dg)
 	spin_lock_irqsave(&vmci_dev_spinlock, flags);
 
 	if (vmci_dev_g) {
-		iowrite8_rep(vmci_dev_g->iobase + VMCI_DATA_OUT_ADDR,
-			     dg, VMCI_DG_SIZE(dg));
+		vmw_iowrite8_rep(vmci_dev_g->iobase + VMCI_DATA_OUT_ADDR,
+				 dg, VMCI_DG_SIZE(dg));
 		result = ioread32(vmci_dev_g->iobase + VMCI_RESULT_LOW_ADDR);
 	} else {
 		result = VMCI_ERROR_UNAVAILABLE;
@@ -216,8 +218,8 @@ static void vmci_dispatch_dgs(unsigned long data)
 
 	BUILD_BUG_ON(VMCI_MAX_DG_SIZE < PAGE_SIZE);
 
-	ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
-		    vmci_dev->data_buffer, current_dg_in_buffer_size);
+	vmw_ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
+			vmci_dev->data_buffer, current_dg_in_buffer_size);
 	dg = (struct vmci_datagram *)dg_in_buffer;
 	remaining_bytes = current_dg_in_buffer_size;
 
@@ -277,7 +279,7 @@ static void vmci_dispatch_dgs(unsigned long data)
 					current_dg_in_buffer_size =
 					    dg_in_buffer_size;
 
-				ioread8_rep(vmci_dev->iobase +
+				vmw_ioread8_rep(vmci_dev->iobase +
 						VMCI_DATA_IN_ADDR,
 					vmci_dev->data_buffer +
 						remaining_bytes,
@@ -319,7 +321,7 @@ static void vmci_dispatch_dgs(unsigned long data)
 				current_dg_in_buffer_size = dg_in_buffer_size;
 
 			for (;;) {
-				ioread8_rep(vmci_dev->iobase +
+				vmw_ioread8_rep(vmci_dev->iobase +
 						VMCI_DATA_IN_ADDR,
 					vmci_dev->data_buffer,
 					current_dg_in_buffer_size);
@@ -339,9 +341,9 @@ static void vmci_dispatch_dgs(unsigned long data)
 		if (remaining_bytes < VMCI_DG_HEADERSIZE) {
 			/* Get the next batch of datagrams. */
 
-			ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
-				    vmci_dev->data_buffer,
-				    current_dg_in_buffer_size);
+			vmw_ioread8_rep(vmci_dev->iobase + VMCI_DATA_IN_ADDR,
+					vmci_dev->data_buffer,
+					current_dg_in_buffer_size);
 			dg = (struct vmci_datagram *)dg_in_buffer;
 			remaining_bytes = current_dg_in_buffer_size;
 		}
diff --git a/include/linux/vmw_vmci_defs.h b/include/linux/vmw_vmci_defs.h
index be0afe6f3..4ef0fb60c 100644
--- a/include/linux/vmw_vmci_defs.h
+++ b/include/linux/vmw_vmci_defs.h
@@ -743,7 +743,12 @@ static inline void *vmci_event_data_payload(struct vmci_event_data *ev_data)
  */
 static inline u64 vmci_q_read_pointer(u64 *var)
 {
-	return READ_ONCE(*(unsigned long *)var);
+	/*
+	 * The virt_load_acquire() barrier ensures that all memory
+	 * accesses after the load cannot be speculated and executed
+	 * before it.
+	 */
+	return virt_load_acquire((unsigned long *)var);
 }
 
 /*
@@ -755,7 +760,11 @@ static inline u64 vmci_q_read_pointer(u64 *var)
 static inline void vmci_q_set_pointer(u64 *var, u64 new_val)
 {
 	/* XXX buggered on big-endian */
-	WRITE_ONCE(*(unsigned long *)var, (unsigned long)new_val);
+	/*
+	 * The virt_store_release() ensures that all memory operations
+	 * done before the store will appear to happen before it.
+	 */
+	virt_store_release((unsigned long *)var, (unsigned long)new_val);
 }
 
 /*
-- 
2.28.0

